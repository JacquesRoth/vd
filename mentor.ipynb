{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Define a function that returns HOG features for an image\n",
    "#\n",
    "from skimage.feature import hog\n",
    "debug = True\n",
    "import cv2\n",
    "def GetHOGFeatures(img, feature_vector):\n",
    "    global debug\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #if debug: print('gray type, shape', type(gray), gray.shape)\n",
    "    # block_norm='L2',\n",
    "    features = hog(gray, orientations=orient,\\\n",
    "                          pixels_per_cell=(pix_per_cell, pix_per_cell),\\\n",
    "                          cells_per_block=(cell_per_block, cell_per_block),\\\n",
    "                          transform_sqrt=True,\\\n",
    "                          feature_vector=False)\n",
    "    if feature_vector: return features.ravel()\n",
    "    #if debug: print('hog features type, shape', type(features), features.shape)\n",
    "\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From lessons\n",
    "import numpy as np\n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=16, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the HSV channels separately\n",
    "    hhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    shist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    vhist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Generating bin centers\n",
    "    bin_edges = hhist[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((hhist[0], shist[0], vhist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    #return hhist, shist, vhist, bin_centers, hist_features\n",
    "    return hist_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Far car image filenames 834 vehicles/GTI_far\\image0000.png\n",
      "Middle close car image filenames 419 vehicles/GTI_MiddleClose\\image0000.png\n",
      "Right car image filenames 664 vehicles/GTI_right\\image0000.png\n",
      "Left car image filenames 909 vehicles/GTI_left\\image0009.png\n",
      "KITTI car image filenames 5966 vehicles/KITTI_extracted\\1.png\n",
      "GTI non-Car image filenames 3900 non-vehicles/GTI\\image1.png\n",
      "Extra non-car image filenames 3900 non-vehicles/GTI\\image1.png\n",
      "Negative Mining non-car files 0\n",
      "rail files 0\n",
      "Car image filenames 8792 vehicles/GTI_far\\image0000.png\n",
      "Total non-Car image filenames 7800 non-vehicles/GTI\\image1.png\n",
      "Cars 8792 Non-Cars 7800\n",
      "Calculating features for color\n",
      "Using 7800 images\n",
      "Lengths 13273 3319 13273 3319 13273 3319\n",
      "Train the Color Support Vector Machine\n",
      "Test the Color Support Vector Machine\n",
      "Color Accuracy =  0.901175052727\n",
      "Calculating HOG features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Miniconda\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16592 HOG features computed\n",
      "Using 7800 images\n",
      "Train the HOG Support Vector Machine\n",
      "len F_train, y_train 13273 13273\n",
      "Test the Support Vector Machine\n",
      "HOG Accuracy =  0.936125338958\n",
      "Train the Color and HOG Support Vector Machine\n",
      "Test the Color Support Vector Machine\n",
      "ColorHOG Accuracy =  0.994275384152\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "#\n",
    "# There is a temptation to use the different sets of car images for\n",
    "# different windows in the image\n",
    "#\n",
    "\n",
    "fCarFiles = glob.glob('vehicles/GTI_far/*.png')\n",
    "print ('Far car image filenames',len(fCarFiles), fCarFiles[0])\n",
    "\n",
    "mCCarFiles = glob.glob('vehicles/GTI_MiddleClose/*.png')\n",
    "print ('Middle close car image filenames',len(mCCarFiles), mCCarFiles[0])\n",
    "\n",
    "rCarFiles = glob.glob('vehicles/GTI_right/*.png')\n",
    "print ('Right car image filenames',len(rCarFiles), rCarFiles[0])\n",
    "\n",
    "lCarFiles = glob.glob('vehicles/GTI_left/*.png')\n",
    "print ('Left car image filenames',len(lCarFiles), lCarFiles[0])\n",
    "\n",
    "kCarFiles = glob.glob('vehicles/KITTI_extracted/*.png')\n",
    "print ('KITTI car image filenames',len(kCarFiles), kCarFiles[0])\n",
    "\n",
    "nonCarFiles = glob.glob('non-vehicles/GTI/*.png')\n",
    "print ('GTI non-Car image filenames',len(nonCarFiles), nonCarFiles[0])\n",
    "\n",
    "nonECarFiles = glob.glob('non-vehicles/GTI/*.png')\n",
    "print ('Extra non-car image filenames',len(nonECarFiles), nonECarFiles[0])\n",
    "\n",
    "negMineCarFiles = glob.glob('negmine/*.png')\n",
    "print ('Negative Mining non-car files',len(negMineCarFiles))\n",
    "railFiles = glob.glob('rail/*.png')\n",
    "print ('rail files',len(railFiles))\n",
    "railFiles = shuffle(railFiles)\n",
    "railFiles = railFiles[0:2000]\n",
    "carFiles = fCarFiles + mCCarFiles + rCarFiles + lCarFiles + kCarFiles\n",
    "print ('Car image filenames',len(carFiles), carFiles[0])\n",
    "\n",
    "nonCarFiles = nonCarFiles + nonECarFiles + negMineCarFiles + railFiles\n",
    "print ('Total non-Car image filenames',len(nonCarFiles), nonCarFiles[0])\n",
    "\n",
    "carFiles = shuffle(carFiles)\n",
    "nonCarFiles = shuffle(nonCarFiles)\n",
    "\n",
    "numImages2Use = min(len(carFiles), len(nonCarFiles))\n",
    "#\n",
    "# Experiment - limit to 5000 of each faster but poor accuracy\n",
    "#\n",
    "#carFiles = carFiles[0:5000]\n",
    "#nonCarFiles = nonCarFiles[0:5000]\n",
    "\n",
    "\n",
    "print('Cars', len(carFiles), 'Non-Cars', len(nonCarFiles))\n",
    "X = carFiles+nonCarFiles\n",
    "y = [True]*len(carFiles)+[False]*len(nonCarFiles)\n",
    "\n",
    "from skimage.feature import hog\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "orient = 9\n",
    "\n",
    "MAX_ITER = -1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "# For each image in the set, create features for color hist\n",
    "#\n",
    "print ('Calculating features for color')\n",
    "Fcolor = []\n",
    "for x in X:\n",
    "    img = cv2.imread(x)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist_features = color_hist(img)\n",
    "    Fcolor += [hist_features]\n",
    "#STACK = np.vstack(Fcolor).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "#Fcolor_scaler = StandardScaler().fit(STACK)\n",
    "# Apply the scaler to STACK\n",
    "#Fcolor = Fcolor_scaler.transform(Fcolor)\n",
    "print('Using', numImages2Use, 'images')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, F_train, F_test = train_test_split(\\\n",
    "    X, y, Fcolor, test_size=0.20)\n",
    "print('Lengths', len(X_train), len(X_test), len(y_train), len(y_test),\\\n",
    "     len(F_train), len(F_test))\n",
    "from sklearn.svm import SVC\n",
    "print('Train the Color Support Vector Machine')\n",
    "clfColor = SVC(max_iter=MAX_ITER)\n",
    "clfColor.fit(F_train, y_train)\n",
    "print('Test the Color Support Vector Machine')\n",
    "pred = clfColor.predict(F_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Color Accuracy = ', acc)\n",
    "#\n",
    "# For each image in the set, create features\n",
    "#\n",
    "print ('Calculating HOG features')\n",
    "F = []\n",
    "for x in X:\n",
    "    img = cv2.imread(x)\n",
    "    features = GetHOGFeatures(img, True)\n",
    "    F += [features]\n",
    "print(len(F), 'HOG features computed')\n",
    "   \n",
    "print('Using', numImages2Use, 'images')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, F_train, F_test = train_test_split(\\\n",
    "    X, y, F, test_size=0.20)\n",
    "from sklearn.svm import SVC\n",
    "print('Train the HOG Support Vector Machine')\n",
    "clf = SVC(max_iter=MAX_ITER)\n",
    "print('len F_train, y_train', len(F_train), len(y_train))\n",
    "clf.fit(F_train, y_train)\n",
    "print('Test the Support Vector Machine')\n",
    "pred = clf.predict(F_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, y_test)\n",
    "\n",
    "print('HOG Accuracy = ', acc)\n",
    "#\n",
    "# Define and train a full model\n",
    "#\n",
    "#\n",
    "# Construct a combined feature vector\n",
    "#\n",
    "\n",
    "FcolorHOG = []\n",
    "i = 0\n",
    "for f1 in Fcolor:\n",
    "    f2 = F[i]\n",
    "    feature_list = [f1, f2]\n",
    "    \n",
    "    # Create an array stack, NOTE: StandardScaler() expects np.float64\n",
    "    #STACK = np.vstack(feature_list).astype(np.float64)\n",
    "    # Fit a per-column scaler\n",
    "    #STACK_scaler = StandardScaler().fit(STACK)\n",
    "    # Apply the scaler to STACK\n",
    "    #scaled_STACK = STACK_scaler.transform(STACK)\n",
    "    #print('f1',f1)\n",
    "    #print('f2',f2)\n",
    "    scaled_STACK = np.concatenate((f1, f2)) # Not NORMALIZED!!!!!\n",
    "    FcolorHOG += [scaled_STACK]\n",
    "    i += 1\n",
    "# Create an array stack, NOTE: StandardScaler() expects np.float64\n",
    "STACK = np.vstack(FcolorHOG).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "STACK_scaler = StandardScaler().fit(STACK)\n",
    "# Apply the scaler to STACK\n",
    "FcolorHOG = STACK_scaler.transform(STACK)\n",
    "X_train, X_test, y_train, y_test, F_train, F_test = train_test_split(\\\n",
    "    X, y, FcolorHOG, test_size=0.20)\n",
    "print('Train the Color and HOG Support Vector Machine')\n",
    "clfColorHOG = SVC(max_iter=MAX_ITER)\n",
    "clfColorHOG.fit(F_train, y_train)\n",
    "print('Test the Color Support Vector Machine')\n",
    "pred = clfColorHOG.predict(F_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('ColorHOG Accuracy = ', acc)\n",
    "#\n",
    "# Try to find optimum parameters\n",
    "#\n",
    "'''\n",
    "from sklearn import svm, grid_search, datasets\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 5, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(F_train, y_train)\n",
    "\n",
    "print('Best paramters', clf.best_params_)\n",
    "print('Test the Best Found Support Vector Machine')\n",
    "pred = clf.predict(F_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, y_test)\n",
    "\n",
    "print('Best Found Accuracy = ', acc)\n",
    "'''\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ColorHOGScalar.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Save the model and the scalar\n",
    "#\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clfColorHOG, 'ColorHOG.pkl')\n",
    "joblib.dump(STACK_scaler, 'ColorHOGScalar.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Load the model\n",
    "#\n",
    "from sklearn.externals import joblib\n",
    "clfCar = joblib.load('ColorHOG.pkl')\n",
    "STACK_scaler = joblib.load('ColorHOGScalar.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Miniconda\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "global find_time, HOG_time, predict_time\n",
    "find_time = 0\n",
    "HOG_time = 0\n",
    "predict_time = 0\n",
    "#\n",
    "# Take some lesson code and modify it to work using my code\n",
    "#\n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "#\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.svm import SVC\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "orient = 9\n",
    "\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block):\n",
    "    global heatmap\n",
    "    global find_time, HOG_time, predict_time\n",
    "    e1 = cv2.getTickCount() #Uncomment for timing analysis\n",
    "    #print('find input image type, shape', type(img),img.shape)\n",
    "    draw_img = np.copy(img)\n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    #print('find img_tosearch type, shape', type(img_tosearch),img_tosearch.shape)\n",
    "    #print('ystart, ystop', ystart, ystop)\n",
    "    gray = img_tosearch #cv2.cvtColor(img_tosearch,cv2.COLOR_BGR2GRAY)\n",
    "    #print('find gray type, shape', type(gray),gray.shape)\n",
    "    hsv  = cv2.cvtColor(img_tosearch, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    \n",
    "    if scale != 1:\n",
    "        imshape = gray.shape\n",
    "        gray = cv2.resize(gray, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        hsv  = cv2.resize(hsv,  (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "    \n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (gray.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (gray.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    e2 = cv2.getTickCount()\n",
    "    hog1 = GetHOGFeatures(gray, False)\n",
    "    HOG_time += cv2.getTickCount() - e2\n",
    "    #print('hog1 type and shape', type(hog1), hog1.shape)\n",
    "\n",
    "   \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_features = hog1[ypos:ypos+nblocks_per_window,\\\n",
    "                                xpos:xpos+nblocks_per_window]\n",
    "            #print('find hog features type and shape', type(hog_features),\\\n",
    "            #      hog_features.shape)\n",
    "            hog_features = hog_features.ravel() \n",
    "            #print('hog_features type', type(hog_features), hog_features.shape)\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(hsv[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            hist_features = np.array(color_hist(subimg))\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "\n",
    "            test_features = X_scaler.transform(np.hstack((hist_features, hog_features)).reshape(1, -1)) \n",
    "            e3 = cv2.getTickCount()\n",
    "            test_prediction = svc.predict(test_features)\n",
    "            predict_time += cv2.getTickCount() - e3\n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                if ((ytop_draw+ystart+win_draw) < img.shape[0]) and \\\n",
    "                    ((xbox_left+win_draw)       < img.shape[1]):\n",
    "                    heatmap[ytop_draw+ystart:ytop_draw+ystart+win_draw,\\\n",
    "                        xbox_left:xbox_left+win_draw] += 0.5 # 1\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),\\\n",
    "                    (xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "    find_time += cv2.getTickCount() - e1                \n",
    "    return draw_img\n",
    "#\n",
    "# Test the find_cars function\n",
    "#\n",
    "ystart = 400\n",
    "ystop  = 656\n",
    "scale = 1.2\n",
    "threshold = 3\n",
    "global heatmap\n",
    "img = cv2.imread('test_images/test6.jpg')\n",
    "heatmap = np.zeros((img.shape[0], img.shape[1]))\n",
    "out_img = find_cars(img, ystart, ystop, scale, clfCar, STACK_scaler, orient, pix_per_cell, cell_per_block)\n",
    "heatmapt = heatmap\n",
    "heatmapt[heatmap <= threshold] = 0\n",
    "labels = label(heatmapt)\n",
    "\n",
    "# Iterate through all detected cars\n",
    "for car_number in range(1, labels[1]+1):\n",
    "    # Find pixels with each car_number label value\n",
    "    nonzero = (labels[0] == car_number).nonzero()\n",
    "    # Identify x and y values of those pixels\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Define a bounding box based on min/max x and y\n",
    "    bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "    # Draw the box on the image\n",
    "    cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"Label Img\", img)\n",
    "cv2.imshow('Find Cars6', out_img)\n",
    "cv2.waitKey(0)\n",
    "'''\n",
    "img = cv2.imread('test_images/test5.jpg')\n",
    "out_img = find_cars(img, ystart, ystop, scale, clfCar, STACK_scaler, orient, pix_per_cell, cell_per_block)\n",
    "cv2.imshow('Find Cars5', out_img)\n",
    "cv2.waitKey(0)\n",
    "img = cv2.imread('test_images/test4.jpg')\n",
    "out_img = find_cars(img, ystart, ystop, scale, clfCar, STACK_scaler, orient, pix_per_cell, cell_per_block)\n",
    "cv2.imshow('Find Cars4', out_img)\n",
    "cv2.waitKey(0)\n",
    "img = cv2.imread('test_images/test3.jpg')\n",
    "out_img = find_cars(img, ystart, ystop, scale, clfCar, STACK_scaler, orient, pix_per_cell, cell_per_block)\n",
    "cv2.imshow('Find Cars3', out_img)\n",
    "cv2.waitKey(0)\n",
    "img = cv2.imread('test_images/test2.jpg')\n",
    "out_img = find_cars(img, ystart, ystop, scale, clfCar, STACK_scaler, orient, pix_per_cell, cell_per_block)\n",
    "cv2.imshow('Find Cars2', out_img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread('test_images/test1.jpg')\n",
    "out_img = find_cars(img, ystart, ystop, scale, clfCar, STACK_scaler, orient, pix_per_cell, cell_per_block)\n",
    "\n",
    "cv2.imshow('Find Cars', out_img)\n",
    "cv2.imwrite('carsfound.jpg', out_img)\n",
    "cv2.waitKey(0)\n",
    "'''\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
